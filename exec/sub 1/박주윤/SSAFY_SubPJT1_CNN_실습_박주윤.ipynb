{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0YfIlcb-Si7"
   },
   "source": [
    "# SSAFY PyTorch project\n",
    "\n",
    "본 과제에서는 딥러닝 분야의 연구에서 가장 많이 사용되는 PyTorch 프레임워크에 익숙해지는 것을 목표로 합니다. PyTorch를 이용하여 분류기 모델을 설계하고, CIFAR-10 데이터셋에 대하여 학습 및 테스트 코드를 작성할 예정입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkdM7Mrf-roV",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "## Colab 사용시\n",
    "\n",
    "실습 시작전에 `Runtime -> Change runtime type` 으로 이동하여 `Hardware Accelerator` 아래 `GPU`을 선택합니다. 해당 항목을 선택함으로 학습 시 GPU를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OMRIrZ3-roS",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "### What is PyTorch?\n",
    "\n",
    "PyTorch is a system for executing dynamic computational graphs over Tensor objects that behave similarly as numpy ndarray. It comes with a powerful automatic differentiation engine that removes the need for manual back-propagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0OElV4u-roT",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "## PyTorch와 관련된 유용한 사이트\n",
    "\n",
    "Justin Johnson 의 PyTorch [튜토리얼](https://github.com/jcjohnson/pytorch-examples).\n",
    "\n",
    "PyTorch의 구체적인 기능을 담은 [API doc](http://pytorch.org/docs/stable/index.html). \n",
    "\n",
    "API docs에서 해결되지 않는 질문들은 [PyTorch forum](https://discuss.pytorch.org/)을 참고."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx7JEzr--roU"
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "본 실습은 총 5개의 파트로 구성되어 있습니다. 실습의 목적은 PyTorch의 3가지 다른 abstraction level을 학습하여 추후 있을 특화 프로젝트를 위해 PyTorch의 함수들에 익숙해지는 것입니다. \n",
    "\n",
    "1. Part I, Preparation: 본 실습에서는 CIFAR-10 dataset을 사용합니다.\n",
    "2. Part II, Barebones PyTorch: **Abstraction level 1**, 가장 low-level의 PyTorch 텐서를 활용해봅니다. \n",
    "3. Part III, PyTorch Module API: **Abstraction level 2**, `nn.Module` 을 활용하여 임의의 딥러닝 모델을 정의합니다. \n",
    "4. Part IV, PyTorch Sequential API: **Abstraction level 3**, `nn.Sequential` 을 활용하여 선형 feed-forward 모델을 정의합니다. \n",
    "5. Part V, CIFAR-10 open-ended challenge: 앞에서 습득한 것을 바탕으로 각자의 모델을 설계하여 CIFAR-10에서 높은 분류 정확도를 달성하는 것을 목표로 합니다. 모델 설계시 특정 레이어를 사용하거나, 학습시 optimizer를 변경하거나, hyperparameter를 튜닝하면서 성능을 높여 봅니다.\n",
    "\n",
    "\n",
    "| API           | Flexibility | Convenience |\n",
    "|---------------|-------------|-------------|\n",
    "| Barebone      | High        | Low         |\n",
    "| `nn.Module`     | High        | Medium      |\n",
    "| `nn.Sequential` | Low         | High        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "osCTyfbi-roV",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1657852504986,
     "user": {
      "displayName": "김성빈",
      "userId": "14941930632185475100"
     },
     "user_tz": -540
    },
    "id": "b7utmcbw-roW",
    "outputId": "fed302bc-10be-40e9-c79d-3efd2bfded12",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # 본 실습에서 float을 사용\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# 학습 시 학습 loss를 출력하는 빈도\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW6tjCkF-roU"
   },
   "source": [
    "# Part I. Preparation\n",
    "\n",
    "## 1. 데이터셋 준비 및 전처리\n",
    "**본 과제에서는 데이터셋으로 CIFAR10을 사용합니다.**\n",
    "\n",
    "CIFAR10은 3x32x32 크기의 이미지로 총 10개의 클래스(‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’) 로 구성된 60000장의 데이터셋입니다. \n",
    "\n",
    "- ``torchvision``을 사용하여 CIFAR10 을 load 할 수 있습니다.\n",
    "- ``torchvision.transform`` 을 사용하여 데이터를 normalize할 수 있습니다.\n",
    "\n",
    "**references**\\\n",
    "dataloader(pytorch doc)\\\n",
    "https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "dataloader parameter(blog)\\\n",
    "https://subinium.github.io/pytorch-dataloader/\n",
    "\n",
    "\n",
    "추가적으로 컴퓨터 비전 데이터를 다룰 때 ``torchvision``이라는 패키지를 사용하면 유용하고, 여러 데이터셋들을 다운 받을 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2329,
     "status": "ok",
     "timestamp": 1657853176997,
     "user": {
      "displayName": "김성빈",
      "userId": "14941930632185475100"
     },
     "user_tz": -540
    },
    "id": "7RuGrfv8-roV",
    "outputId": "98683699-4ad3-4d93-f74f-db3ee9ea6b06",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Req. 1-1\t데이터셋 준비 및 전처리, 시각화\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "# torchvision.transforms 내에는 데이터 전처리 및 data augmentation을 위한 패키지를 제공\n",
    "# 본 실습에서 [0,1] 범위의 데이터셋을 [-1, -1] 범위의 값으로 normalize하도록 transform 정의\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "\n",
    "# Dataset을 (train / val / test)으로 분리\n",
    "# 분리된 Datasets를 DataLoader로 wrap하여, 추후 각 data들이 매 iteration마다 미니배치로 제공됨\n",
    "cifar10_train = dset.CIFAR10('./cores/datasets/', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cores/datasets/', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cores/datasets/', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "\n",
    "# CIFAR10의 10개의 class 정의\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfvkaZyQsxbe"
   },
   "source": [
    "### 데이터 시각화\n",
    "- ``matplotlib``는 python visualization library\n",
    "- ``matplotlib``의 imshow 함수를 데이터들을 시각화 할 수 있습니다.\n",
    "\n",
    "\n",
    "**references**\n",
    "\n",
    "matplotlib doc\\\n",
    "https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1657853179524,
     "user": {
      "displayName": "김성빈",
      "userId": "14941930632185475100"
     },
     "user_tz": -540
    },
    "id": "6LbGKNdKs2Ug",
    "outputId": "c3f13a01-279b-4104-930e-1d851d3de488"
   },
   "outputs": [],
   "source": [
    " # 이미지를 시각화하는 함수\n",
    "def visualize(img):\n",
    "    ################################################################################\n",
    "    # TODO: 시각화를 위한 코드 작성.                                                    #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # 1) [-1, -1] 범위로 normalize된 데이터를 [0,1] 범위로 unnormalize \n",
    "    img = img / 2 + 0.5\n",
    "    # 2) img를 numpy값으로 변환\n",
    "    np_img = img.numpy()\n",
    "    # 3) plt.imshow함수로 시각화\n",
    "    plt.imshow(np.transpose(np_img, (1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    \n",
    "# 트레이닝 데이터를 랜덤 샘플\n",
    "dataiter = iter(loader_train)\n",
    "images, labels = dataiter.next() ## image\n",
    "\n",
    "# show images\n",
    "visualize(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBV76xLh-roW"
   },
   "source": [
    "# Part II. Barebones PyTorch\n",
    "\n",
    "PyTorch는 모델 아키텍처를 편리하게 정의할 수 있도록 high-level API와 함께 제공합니다. 본 파트에서는 high-level API를 다루기 전에 barebone PyTorch 부터 시작하여 autograd 엔진을 더 잘 이해할 수 있도록 합니다. \n",
    "\n",
    "우리는 CIFAR-10 분류를 위해 두 개의 레이어와 ReLU로 구성된 간단한 fully-connected 네트워크로 시작합니다. 본 실습에서는 PyTorch Tensor의 연산을 사용하여 forward 패스를 계산하고 PyTorch autograd를 사용하여 backward 패스의 그레이디언트를 계산합니다.\n",
    "\n",
    "`requires_grad=True`로 PyTorch Tensor를 생성하면 해당 텐서는 단순히 값을 계산하는 연산만 하는 것이 아니라 백그라운드에서 계산 그래프를 구축하여 loss와 관련된 텐서의 그레이디언트 계산합니다. 구체적으로, 만약 x가 `x.requires_grad == True`인 Tensor라면, 역전파 후 `x.grad`는 마지막에 스칼라 loss값과 관련하여 x의 그레디언트를 기록하는 또 다른 Tensor가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Um_TYvC-roX",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "### PyTorch Tensors: Flatten 함수\n",
    "PyTorch Tensor는 numpy array와 유사합니다. numpy와 마찬가지로 PyTorch에서도 효율적인 Tensor 연산을 위해 많은 함수들을 제공합니다. 간단한 예로, fully-connected 네트워크에 이미지 입력을 위하여 이미지 데이터를 reshape하는 `flatten` 함수를 제공합니다. \n",
    "\n",
    "이미지 데이터는 일반적으로 N x C x H x W 형태의 Tensor로 저장됩니다. 여기서, \n",
    "\n",
    "* N is the number of datapoints\n",
    "* C is the number of channels\n",
    "* H is the height of the intermediate feature map in pixels\n",
    "* W is the height of the intermediate feature map in pixels\n",
    "\n",
    "위의 Tensor 형태의 경우, 2D 컨볼루션과 같은 공간적 이해를 필요로 하는 레이어를 적용할때 적절한 데이터 형태 입니다. 그러나 fully-connected 네트워크를 사용하여 이미지 데이터를 처리할 때 각 데이터가 단일 벡터로 표현되어야 합니다. 따라서 데이터 당 `C x H x W`값을 하나의 긴 벡터 형태로 변환해주기 위해 \"flatten\" 연산을 사용합니다. \"flatten\" 함수는 먼저 주어진 데이터 배치에서 N, C, H 및 W 값을 읽은 다음 해당 데이터의 \"view\"를 반환합니다. \"view\"는 numpy의 \"reshape\" 방법과 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olu7NinT-roX",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))\n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAO5BzFf-roY",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "### Barebones PyTorch: Two-Layer Network\n",
    "\n",
    "Forward 패스를 수행하는 두개의 레이어를 가진 fully-connected ReLU 모델을 `two_layer_fc`의 이름으로 정의합니다. 정의한 이후 모델이 잘 동작하는지 확인하기 위해 zeros 값을 넣어봅니다. 본 실습에서는 별도로 코드를 작성하진 않지만, 구현된 코드를 자세히 읽어보고 다 이해하도록 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOCxY_lf-roY",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "def two_layer_fc(x, params):\n",
    "    \"\"\"\n",
    "    Fully-connected 네트워크는 다음과 같이 구성되어 있습니다:\n",
    "    fully connected -> ReLU -> fully connected layer.\n",
    "    위의 정의는 forward 패스만 구현한 것이고, backward 패스는 PyTorch가 자동으로 구현합니다.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n",
    "      input data.\n",
    "    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n",
    "      w1 has shape (D, H) and w2 has shape (H, C).\n",
    "    \n",
    "    Returns:\n",
    "    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n",
    "      the input data x.\n",
    "    \"\"\"\n",
    "    # 먼저 이미지를 flatten 합니다.\n",
    "    x = flatten(x)  # shape: [batch_size, C x H x W]\n",
    "    \n",
    "    w1, w2 = params\n",
    "    \n",
    "    # Forward 패스: Tensor에 정의된 operation을 활용하여 y값을 예측합니다.\n",
    "    # w1과 w2는 requires_grad=True로 되어 있기 때문에 자동으로 계산 그래프를 구축하여\n",
    "    # 자동으로 gradient값을 계산할 수 있습니다. \n",
    "    # 따라서 수동으로 backward 패스를 구현하지 않아도 됩니다.\n",
    "    \n",
    "    x = F.relu(x.mm(w1))\n",
    "    x = x.mm(w2)\n",
    "    return x\n",
    "\n",
    "\n",
    "def two_layer_fc_test():\n",
    "    hidden_layer_size = 42\n",
    "    x = torch.zeros((64, 50), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
    "    \n",
    "    # weight값 초기화\n",
    "    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype, requires_grad=True)\n",
    "    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype, requires_grad=True)\n",
    "\n",
    "    scores = two_layer_fc(x, [w1, w2])\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "\n",
    "two_layer_fc_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dm-wQVV4-roY"
   },
   "source": [
    "### Barebones PyTorch: Three-Layer ConvNet\n",
    "\n",
    "Forward 패스를 수행하는 세개의 컨볼루션 레이어를 가진 모델을 `three_layer_convnet`의 이름으로 정의합니다. 앞선 실습과 마찬가지로 정의한 모델이 잘 동작하는 지 확인하기 위해 zero 값을 넣어봅니다. 네트워크 아키텍쳐는 다음과 같아야 합니다.\n",
    "\n",
    "1. A convolutional layer (with bias) with `channel_1` filters, each with shape `KW1 x KH1`, and zero-padding of two\n",
    "2. ReLU nonlinearity\n",
    "3. A convolutional layer (with bias) with `channel_2` filters, each with shape `KW2 x KH2`, and zero-padding of one\n",
    "4. ReLU nonlinearity\n",
    "5. Fully-connected layer with bias, producing scores for C classes.\n",
    "\n",
    "본 실습에서는 마지막 fully-connected layer 이후에 **softmax activation**이 없습니다. 이는 PyTorch의 cross entropy loss가 자동으로 softmax activation을 연산해주기 때문입니다.\n",
    "\n",
    "**HINT**: For convolutions: http://pytorch.org/docs/stable/nn.html#torch.nn.functional.conv2d; pay attention to the shapes of convolutional filters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdLGSosS-roZ"
   },
   "outputs": [],
   "source": [
    "# Req. 1-2\tThree-Layer ConvNet 의 forward 패스 Tensor 연산으로 설계하기\n",
    "def three_layer_convnet(x, params):\n",
    "    \"\"\"\n",
    "    아래 정의된 모델은 3개의 컨볼루션 레이어를 갖는 네트워크의 forward 패스를 수행합니다.\n",
    "\n",
    "    Inputs:\n",
    "    - x: 이미지의 minibatch로 구성된 (N, 3, H, W) shape의 PyTorch 텐서\n",
    "    - params: 네트워크의 weights와 biases를 담은 PyTorch 텐서의 리스트, 아래 내용들 포함\n",
    "      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n",
    "        for the first convolutional layer\n",
    "      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n",
    "        convolutional layer\n",
    "      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n",
    "        weights for the second convolutional layer\n",
    "      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n",
    "        convolutional layer\n",
    "      - fc_w: PyTorch Tensor giving weights for the fully-connected layer.\n",
    "      - fc_b: PyTorch Tensor giving biases for the fully-connected layer.\n",
    "    \n",
    "    Returns:\n",
    "    - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n",
    "    \"\"\"\n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    scores = None\n",
    "    ################################################################################\n",
    "    # TODO: Implement the forward pass for the three-layer ConvNet.                #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    conv_1 = F.conv2d(x, weight=conv_w1, bias=conv_b1, padding=2)\n",
    "    relu_1 = F.relu(conv_1)\n",
    "    conv_2 = F.conv2d(relu_1, weight=conv_w2, bias=conv_b2, padding=1)\n",
    "    relu_2 = F.relu(conv_2)\n",
    "    relu_2_flat = flatten(relu_2)\n",
    "    scores = relu_2_flat.mm(fc_w) + fc_b\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMOpPXug-roZ"
   },
   "source": [
    "Forward 패스에 해당하는 ConvNet을 정의한 이후 다음 cell을 실행하여 구현한 코드를 확인해봅니다.\n",
    "\n",
    "다음 함수를 실행하면, (64,10) shape을 갖는 score값을 출력하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "barebones_output_shape",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def three_layer_convnet_test():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "\n",
    "    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype, requires_grad=True)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b1 = torch.zeros((6,), requires_grad=True)  # out_channel\n",
    "    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype, requires_grad=True)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b2 = torch.zeros((9,), requires_grad=True)  # out_channel\n",
    "\n",
    "    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n",
    "    fc_w = torch.zeros((9 * 32 * 32, 10), requires_grad=True)\n",
    "    fc_b = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "three_layer_convnet_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7V2HcTY-roZ"
   },
   "source": [
    "### Barebones PyTorch: Initialization\n",
    "몇가지 utility 메소드를 활용하여 모델의 weight matrices를 초기화해봅니다.\n",
    "\n",
    "- `random_weight(shape)` 은 weight값을 Kaiming normalization method로 초기화 합니다. \n",
    "\n",
    "- `zero_weight(shape)` 은 wieght값을 0으로 초기화 합니다.\n",
    "\n",
    "`random_weight` 함수는 Kaiming normal initialization method로, 아래의 논문을 참고하면 됩니다:\n",
    "\n",
    "He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWeDBMzJ-roa",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def random_weight(shape):\n",
    "    \"\"\"\n",
    "    Weight을 위한 랜덤 텐서를 생성합니다. 이때 requires_grad=True로 세팅해주어야 \n",
    "    추후에 backward 패스에서 사용할 gradient를 자동으로 계산할 수 있습니다.\n",
    "    여기서 Kaiming normalization을 사용합니다: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:  # FC weight\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
    "    # randn is standard normal distribution generator. \n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "def zero_weight(shape):\n",
    "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# create a weight of shape [3 x 5]\n",
    "# you should see the type `torch.cuda.FloatTensor` if you use GPU. \n",
    "# Otherwise it should be `torch.FloatTensor`\n",
    "random_weight((3, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8hQD1gf-roa"
   },
   "source": [
    "### Barebones PyTorch: Check Accuracy\n",
    "모델을 학습할 때 다음의 함수를 활용하여 모델의 정확성을 확인합니다. 정확도를 확인할 때에는 gradient를 계산할 필요가 없습니다. 따라서 `torch.no_grad()`를 입력하여 계산 그래프의 gradient 계산을 막습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pF3TnaZS-roa",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def check_accuracy_part2(loader, model_fn, params):\n",
    "    \"\"\"\n",
    "    분류 모델의 정확성 측정\n",
    "    \n",
    "    Inputs:\n",
    "    - loader: A DataLoader for the data split we want to check\n",
    "    - model_fn: A function that performs the forward pass of the model,\n",
    "      with the signature scores = model_fn(x, params)\n",
    "    - params: List of PyTorch Tensors giving parameters of the model\n",
    "    \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    split = 'val' if loader.dataset.train else 'test'\n",
    "    print('Checking accuracy on the %s set' % split)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    with torch.no_grad(): # gradient 계산할 필요가 없어, computational graph 를 그리지 않게 하기위해 with torch.no_grad() 사용\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "            scores = model_fn(x, params)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssMY8d-L-roa"
   },
   "source": [
    "### BareBones PyTorch: Training Loop\n",
    "이제 학습 loop를 작성하여 네트워크를 학습합니다. 학습은 stochastic gradient descent를 사용합니다. 또한 `torch.functional.cross_entropy` 를 사용하여 loss를 측정합니다 [read about it here](http://pytorch.org/docs/stable/nn.html#cross-entropy).\n",
    "\n",
    "학습 loop는 네트워크 함수와 초기화된 weight 파라미터 (`[w1, w2]` in our example), 그리고 learning rate을 입력으로 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmRJTwiS-rob",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def train_part2(model_fn, params, learning_rate):\n",
    "    \"\"\"\n",
    "    CIFAR-10에 대하여 모델 학습하기.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_fn: 모델의 forward 패스를 수행하는 PyTorch 함수.\n",
    "      이는 이미지 데이터 x와 모델 weight의 list를 입력으로 받아 score를 출력하는 함수이다.\n",
    "      scores = model_fn(x, params)\n",
    "    - params: 모델 weight의 list\n",
    "    - learning_rate: scalar 값\n",
    "    \n",
    "    Returns: Nothing\n",
    "    \"\"\"\n",
    "    for t, (x, y) in enumerate(loader_train):\n",
    "        # 데이터를 적절한 device에 올리기\n",
    "        x = x.to(device=device, dtype=dtype)\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "        # Forward 패스를 수행하고, loss 계산하기\n",
    "        scores = model_fn(x, params)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        # Backward 패스 수행\n",
    "        loss.backward()\n",
    "\n",
    "        # 모델의 weight 업데이트하기. wieght 업데이트 시에는 gradient 계산은 \n",
    "        # torch.no_grad()를 사용하여 막는다\n",
    "        with torch.no_grad():\n",
    "            for w in params:\n",
    "                w -= learning_rate * w.grad\n",
    "\n",
    "                # Backward 패스를 마친 이후 수동으로 gradient 값을 0으로 초기화\n",
    "                w.grad.zero_()\n",
    "\n",
    "        if t % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "            check_accuracy_part2(loader_val, model_fn, params)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaFNxBVX-rob"
   },
   "source": [
    "### BareBones PyTorch: Train a Two-Layer Network\n",
    "이제 학습 loop 실행을 시작합니다. 먼저 앞서 정의한 weight 초기화 함수를 활용하여 `w1`와 `w2`를 정의합니다. \n",
    "\n",
    "CIFAR-10의 각 미니배치의 Tensor shape은 `[64, 3, 32, 32]` 입니다.\n",
    "\n",
    "이미지 데이터 `x`를 flatten한 뒤에 shape은 `[64, 3 * 32 * 32]`가 되어야 합니다. 이는 `w1`의 첫 dimension의 사이즈와 동일합니다. `w1`의 두번째 dimension의 사이즈는 hidden 레이어의 사이즈와 동일하고, 이는 동시에 `w2`의 첫 dimension의 사이즈와 동일합니다. \n",
    "\n",
    "마지막으로, 네트워크의 출력은 10-dimensional vector이고, 이는 10개 클래스에 대한 확률을 나타냅니다.\n",
    "\n",
    "별도로 hyperparameters를 수정하지 않고도 한 에폭 이후 40% 이상의 분류 정확도를 보이면 성공입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCUblJMn-rob"
   },
   "outputs": [],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n",
    "w2 = random_weight((hidden_layer_size, 10))\n",
    "\n",
    "\n",
    "train_part2(two_layer_fc, [w1, w2], learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIlTf7EZ-rob"
   },
   "source": [
    "### BareBones PyTorch: Training a ConvNet\n",
    "\n",
    "Two-layer 네트워크 학습이 마쳤다면, 여기에서는 ConvNet을 학습시켜 봅니다. 여기서 정의해야할 네트워크는 다음과 같은 구조를 가져야 합니다.\n",
    "\n",
    "1. Convolutional layer (with bias) with 32 5x5 filters, with zero-padding of 2\n",
    "2. ReLU\n",
    "3. Convolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1\n",
    "4. ReLU\n",
    "5. Fully-connected layer (with bias) to compute scores for 10 classes\n",
    "\n",
    "모든 weight matrices는 앞서 정의한 `random_weight` 함수를 사용하여 초기화 시켜 주어야 하고, bias vector는 `zero_weight` 함수로 초기화 시켜 줍니다.\n",
    "\n",
    "별도로 hyperparameters를 수정하지 않고도 한 에폭 이후 42% 이상의 분류 정확도를 보이면 성공입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "barebones_accuracy"
   },
   "outputs": [],
   "source": [
    "# Req. 1-3\tThree-Layer ConvNet의 weight 파라미터를 Tensor 형태로 초기화\n",
    "\n",
    "learning_rate = 3e-3\n",
    "\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "conv_w1 = None\n",
    "conv_b1 = None\n",
    "conv_w2 = None\n",
    "conv_b2 = None\n",
    "fc_w = None\n",
    "fc_b = None\n",
    "\n",
    "################################################################################\n",
    "# TODO: Initialize the parameters of a three-layer ConvNet.                    #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "conv_w1 = random_weight((channel_1, 3, 5, 5))\n",
    "conv_b1 = zero_weight((channel_1))\n",
    "\n",
    "conv_w2 = random_weight((channel_2, 32, 3, 3))\n",
    "conv_b2 = zero_weight((channel_2))\n",
    "\n",
    "fc_w = random_weight((channel_2 * 32 * 32, 10))\n",
    "fc_b = zero_weight((10))\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "train_part2(three_layer_convnet, params, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zgw7wn11-roc"
   },
   "source": [
    "# Part III. PyTorch Module API\n",
    "\n",
    "Barebone PyTorch에서는 모든 파라미터 텐서들을 직접 관리했습니다. 작은 네트워크일 경우일때는 괜찮지만, 네트워크가 커질수록 직접 파라미터 하나하나 정의하고 관리하기에는 불가능합니다.\n",
    "\n",
    "PyTorch는 `nn.Module` API를 제공하여 직접 임의의 네트워크를 정의할 수 있고 학습 가능한 파라미터를 자동으로 추적할 수 있게 도와줍니다. Part II에서는 SGD를 직접 구현했지만 PyTorch는 `torch.optim` 패키지를 제공하여 SGD와 더불어 다양한 optimizer를 사용할수 있게 합니다. 다음의 자료 [doc](http://pytorch.org/docs/master/optim.html)를 참고하여 다양한 optimizer의 정의를 살펴보길 바랍니다.\n",
    "\n",
    "Module API를 사용하기 위해서 아래의 step을 따라야 합니다:\n",
    "\n",
    "1. Subclass `nn.Module`. `nn.Module`를 상속받아 `TwoLayerFC`와 같은 직관적인 이름으로 네트워크 클래스 정의. \n",
    "\n",
    "2. 정의한 클래스의 `__init__()`에서 모델을 구성하는 모든 레이어에 대해서 정의합니다. `nn.Linear`와 `nn.Conv2d`는 `nn.Module`의 subclasses로 학습 가능한 파라미터를 포함하고 있어 별도로 Tensor를 초기화하지 않아도 됩니다. 다양한 builtin 레이어들에 대해 공부하고 싶다면 다음 자료 [doc](http://pytorch.org/docs/master/nn.html)를 참고시길 바랍니다. **Warning**: 클래스 정의시 `super().__init__()`를 가장 먼저 호출합니다.\n",
    "\n",
    "3. `forward()` method에서는 네트워크 내 레이어들의 연결들을 정의해주어야 합니다. 앞선 `__init__`에서 정의한 레이어들을 입력과 출력 shape에 맞는 레이어들로 연결해줍니다. `forward()`에서는 새로운 학습 가능한 파라미터를 생성하면 안됩니다. 모든 파라미터 생성은 `__init__`에서 만들어져야 합니다.\n",
    "\n",
    "\n",
    "### Module API: Two-Layer Network\n",
    "아래는 2개의 레이어를 갖는 fully-connected 네트워크의 구체적인 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaR00Yty-roc"
   },
   "outputs": [],
   "source": [
    "class TwoLayerFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        # 레이어 2개를 정의합니다.\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # nn.init 패키지 내에서 초기화 함수를 사용합니다.\n",
    "        # http://pytorch.org/docs/master/nn.html#torch-nn-init \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward 에서는 레이어의 연결을 정의합니다.\n",
    "        x = flatten(x)\n",
    "        scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        return scores\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    input_size = 50\n",
    "    x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
    "    model = TwoLayerFC(input_size, 42, 10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "\n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOpjTQTn-roc"
   },
   "source": [
    "### Module API: Three-Layer ConvNet\n",
    "이제 여기서는 3개의 컨볼루션 레이어와 fully-connected 레이어를 갖는 ConvNet를 직접 구현해 봅니다. 네트워크의 구조는 Part II에서 정의한 것과 동일합니다:\n",
    "\n",
    "1. Convolutional layer with `channel_1` 5x5 filters with zero-padding of 2\n",
    "2. ReLU\n",
    "3. Convolutional layer with `channel_2` 3x3 filters with zero-padding of 1\n",
    "4. ReLU\n",
    "5. Fully-connected layer to `num_classes` classes\n",
    "\n",
    "Kaiming normal initialization method를 활용하여 정의한 레이어들을 초기화 합니다.\n",
    "\n",
    "**HINT**: http://pytorch.org/docs/stable/nn.html#conv2d\n",
    "\n",
    "ConvNet를 구현한 이후, `test_ThreeLayerConvNet` 함수를 실행하면`(64, 10)` shape 의 output score를 출력하게 됩니다.\n",
    "\n",
    "### Pytorch functions\n",
    "- ``nn.Conv2d`` : torch.nn.Conv2d(in_channels: int, out_channels: int, kernel_size, stride = 1, padding = 0)\n",
    "- ``nn.Maxpool2d`` : torch.nn.MaxPool2d(kernel_size, stride = None, padding = 0)\n",
    "- ``nn.Linear`` : torch.nn.Linear(in_features: int, out_features: int, bias: bool = True)\n",
    "\n",
    "\n",
    "**references**\n",
    "\n",
    "https://tutorials.pytorch.kr/beginner/examples_nn/two_layer_net_module.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "\n",
    "**tips**\n",
    "\n",
    "http://taewan.kim/post/cnn/\n",
    "\n",
    "http://taewan.kim/post/cnn/#4-cnn-%EC%9E%85%EC%B6%9C%EB%A0%A5-%ED%8C%8C%EB%A6%AC%EB%AF%B8%ED%84%B0-%EA%B3%84%EC%82%B0\n",
    "\n",
    "https://mrsyee.github.io/image%20processing/2018/11/28/cnn_technique/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "module_output_shape"
   },
   "outputs": [],
   "source": [
    "# Req. 1-4\tThree-Layer ConvNet 클래스를 Module API를 활용하여 정의하기\n",
    "\n",
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
    "        # architecture defined above.                                          #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.conv1=nn.Conv2d(in_channel,channel_1,[5,5],padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.conv2=nn.Conv2d(channel_1,channel_2,[3,3],padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.fc=nn.Linear(channel_2*32*32,num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #       \n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
    "        # should use the layers you defined in __init__ and specify the        #\n",
    "        # connectivity of those layers in forward()                            #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x1=self.conv1(x)\n",
    "        r1=nn.functional.relu(x1)\n",
    "        x2=self.conv2(r1)\n",
    "        r2=nn.functional.relu(x2)\n",
    "        scores=self.fc(r2.view([-1,np.prod(r2.shape[1:])]))\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                             END OF YOUR CODE                         #\n",
    "        ########################################################################\n",
    "        return scores\n",
    "\n",
    "\n",
    "\n",
    "def test_ThreeLayerConvNet():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGCVr-HL-roc"
   },
   "source": [
    "### Module API: Check Accuracy\n",
    "Validation이나 test set이 주어졌을 때 분류 정확도를 측정합니다.\n",
    "\n",
    "해당 버전은 수동으로 파라미터를 전달했던 part II와는 약간 다릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCJpN5w3-roc"
   },
   "outputs": [],
   "source": [
    "# Req. 1-5\tModule API에서 성능 평가 함수 구현하기\n",
    "\n",
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    ########################################################################\n",
    "    # TODO: Implement the function for evaluating the accuracy of the model#\n",
    "    ########################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ########################################################################\n",
    "    #                          END OF YOUR CODE                            #       \n",
    "    ########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntKnTuU8-roc"
   },
   "source": [
    "### Module API: Training Loop\n",
    "\n",
    "학습 loop를 작성합니다. 직접 파라미터를 업데이트하기 위한 코드를 작성하지 않고, `torch.optim` 패키지 내의 optimizer를 사용하여 자동으로 파라미터를 업데이트 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XFYlAlc-rod"
   },
   "outputs": [],
   "source": [
    "# Req. 1-6\tModule API에서 학습 loop 구현하기\n",
    "\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    ########################################################################\n",
    "    # TODO: Implement the training loop                                    #\n",
    "    ########################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()\n",
    "\n",
    "    # 1) 첫번째 for문으로 epochs 만큼 반복\n",
    "    # 2) 두번째 for문으로 trainset이 저장되어 있는 loader_train에서 배치 사이즈 만큼씩 data load\n",
    "    # 3) load한 data에서 input 값과 label을 device에 올림 (GPU or CPU)\n",
    "    # 4) model에 input값을 입력하여 forward 패스 수행\n",
    "    # 5) loss function으로 예측값과 label 비교\n",
    "    # 6) optimizer에서 gradient 값 0으로 초기화\n",
    "    # 7) loss 값 backpropagation 하여 gradient 계산\n",
    "    # 8) Optimizer 업데이트\n",
    "    # 9) loss와 accuracy를 print_every 주기 마다 출력\n",
    "    # 10) 2)로 돌아가 반복 한뒤 2)가 모두 마치면 1)로 돌아가 반복\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ########################################################################\n",
    "    #                          END OF YOUR CODE                            #       \n",
    "    ########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxONnBns-rod"
   },
   "source": [
    "### Module API: Train a Two-Layer Network\n",
    "이제 학습 loop 실행을 시작합니다. Part II와 다르게 파라미터를 직접 정의하지 않아도 됩니다.\n",
    "\n",
    "Input size, hidden 레이어 size, output size(클래스 개수)를 입력하여 `TwoLayerFC`의 객체를 생성합니다.\n",
    "\n",
    "또한 `TwoLayerFC`의 학습 가능한 파라미터를 추적하기 위한 optimizer 또한 정의합니다.\n",
    "\n",
    "별도로 hyperparameters를 수정하지 않고도 한 에폭 이후 40% 이상의 분류 정확도를 보이면 성공입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXqbIpZh-rod"
   },
   "outputs": [],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "model = TwoLayerFC(3 * 32 * 32, hidden_layer_size, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTSpUGnh-rod"
   },
   "source": [
    "### Module API: Train a Three-Layer ConvNet\n",
    "이제 Module API를 사용하여 직접 three-layer ConvNet을 설계합니다. 앞선 two-layer 네트워크와 비슷할 것 입니다. 별도로 hyperparameters를 수정하지 않고도 한 에폭 이후 40% 이상의 분류 정확도를 보이면 성공입니다. 모델 학습 시 stochastic gradient descent를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "module_accuracy"
   },
   "outputs": [],
   "source": [
    " # Req. 1-7\tThreeLayerConvNet의 instance만들고 optimizer 정의\n",
    "\n",
    "learning_rate = 3e-3\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "################################################################################\n",
    "# TODO: Instantiate your ThreeLayerConvNet model and a corresponding optimizer #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model=ThreeLayerConvNet(3,channel_1,channel_2,10)\n",
    "optimizer=optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             \n",
    "################################################################################\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-gD1xhA-rod"
   },
   "source": [
    "# Part IV. PyTorch Sequential API\n",
    "\n",
    "Feed forward layers가 여러개 쌓여져 있는 간단한 모델의 경우에도 다음과 같이 3가지 step을 따라야 합니다: subclass `nn.Module`, assign layers to class attributes in `__init__`, and call each layer one by one in `forward()`. 본 파트에서는 이보다 더 간단한 방법을 제공합니다. \n",
    "\n",
    "PyTorch 는 `nn.Sequential`라는 container Module을 제공하고, 이는 위의 3가지 step을 하나로 합쳐 줍니다.\n",
    "\n",
    "### Sequential API: Two-Layer Network\n",
    "먼저 `nn.Sequential`를 사용하여 two-layer 네트워크를 다시 정의하고, 앞서 정의한 학습 loop로 학습시켜 봅니다.\n",
    "\n",
    "별도로 hyperparameters를 수정하지 않고도 한 에폭 이후 40% 이상의 분류 정확도를 보이면 성공입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDshtI4P-rod"
   },
   "outputs": [],
   "source": [
    "# We need to wrap `flatten` function in a module in order to stack it\n",
    "# in nn.Sequential\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size, 10),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uY_DSY_T-roe"
   },
   "source": [
    "### Sequential API: Three-Layer ConvNet\n",
    "이제 `nn.Sequential`를 활용하여 Part III와 동일한 구조의 three-layer ConvNet를 직접 정의하고 학습시켜 봅니다:\n",
    "\n",
    "1. Convolutional layer (with bias) with 32 5x5 filters, with zero-padding of 2\n",
    "2. ReLU\n",
    "3. Convolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1\n",
    "4. ReLU\n",
    "5. Fully-connected layer (with bias) to compute scores for 10 classes\n",
    "\n",
    "Weight matrices는 앞서 정의한 `random_weight` 함수로 초기화 하고 bias vectors `zero_weight` 함수로 초기화 합니다.\n",
    "\n",
    "Optimizer로는 Nesterov momentum 0.9를 갖는 stochastic gradient descent를 사용합니다.\n",
    "\n",
    "별도로 hyperparameters를 수정하지 않고도 한 에폭 이후 55% 이상의 분류 정확도를 보이면 성공입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sequential_accuracy"
   },
   "outputs": [],
   "source": [
    "# Req. 1-8\tThreeLayerConvNet을 Sequential API로 구현하기\n",
    "\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "################################################################################\n",
    "# TODO: Rewrite the 3-layer ConvNet with bias from Part III with the           #\n",
    "# Sequential API.                                                              #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model=nn.Sequential(\n",
    "    nn.Conv2d(3,channel_1,5,padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1,channel_2,3,padding=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*32*32,10)\n",
    ")\n",
    "# for i in model.parameters():\n",
    "    # nn.init.kaiming_normal_(i)\n",
    "for i in model.modules():\n",
    "    if isinstance(i,nn.Conv2d):\n",
    "        i.weight=nn.Parameter(random_weight(i.weight.shape))\n",
    "        i.bias=nn.Parameter(zero_weight(i.bias.shape))\n",
    "optimizer=optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9)\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             \n",
    "################################################################################\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc85YLFs-roe"
   },
   "source": [
    "# Part V. CIFAR-10 open-ended challenge\n",
    "\n",
    "본 파트에서는 자유롭게 ConvNet을 설계하여 CIFAR-10을 학습시켜 높은 분류 정확도를 달성하는 것을 목표로 합니다. \n",
    "\n",
    "여기에서는 모델 아키텍쳐, hyperparameter, loss function, optimizer 등을 다양하게 바꿔가며 실험하면서 모델을 학습시켜 CIFAR-10에 대하여 10개의 epoch내에서 validation set의 **최소 70% 이상**의 정확도를 달성합니다. 실험시 앞에서 학습했던 `nn.Module` 혹은 `nn.Sequential` API을 활용합니다. \n",
    "\n",
    "참고자료:\n",
    "* Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html\n",
    "* Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n",
    "* Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "* Optimizers: http://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "\n",
    "### 시도할 수 있는 것:\n",
    "- **Filter size**: Above we used 5x5; would smaller filters be more efficient?\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "### Going above and beyond\n",
    "- Alternative optimizers: you can try Adam, Adagrad, RMSprop, etc.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMaHX8booiD7"
   },
   "outputs": [],
   "source": [
    "# Req. 1-9\t다양한 실험을 통해 성능 끌어 올리기\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #         \n",
    "# Experiment with any architectures, optimizers, and hyperparameters.          #\n",
    "# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n",
    "#                                                                              #\n",
    "# Note that you can use the check_accuracy function to evaluate on either      #\n",
    "# the test set or the validation set, by passing either loader_test or         #\n",
    "# loader_val as the second argument to check_accuracy. You should not touch    #\n",
    "# the test set until you have finished your architecture and  hyperparameter   #\n",
    "# tuning, and only run the test set once at the end to report a final value.   #\n",
    "################################################################################\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             \n",
    "################################################################################\n",
    "\n",
    "# You should get at least 70% accuracy\n",
    "train_part34(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs_wLpVK-roe"
   },
   "source": [
    "## Test set -- run this only once\n",
    "\n",
    "Validation에서 만족스러운 성능을 얻었다면, 마지막으로 test set에 대해서 학습된 모델을 평가해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joDKAIg1-rof"
   },
   "outputs": [],
   "source": [
    "best_model = model\n",
    "check_accuracy_part34(loader_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qn05j4w6IjgL"
   },
   "outputs": [],
   "source": [
    "print('# parameters : ', sum(p.numel() for p in best_model.parameters() if p.requires_grad))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1bG7mQEA0gBOHounPzq4Cp5WYYjegHKcH",
     "timestamp": 1662306853514
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
